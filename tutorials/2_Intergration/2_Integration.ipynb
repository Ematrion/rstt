{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a784930b-9ef3-4305-99c6-946b53669eae",
   "metadata": {},
   "source": [
    "# RSTT Tutorial 2 - Integration\n",
    "\n",
    "In this notebook we will use the [openskill](https://openskill.me/en/stable/) rating system with RSTT.\n",
    "The goal is to wrapp model in a Ranking class to benefit from its functionnalities and fit in simulation.\n",
    "We will also use model predictions to generate games outcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5d91d-45c5-4833-bc44-8965adc76db1",
   "metadata": {},
   "source": [
    "## 1. RSTT Ranking Design \n",
    "\n",
    "A [Ranking](https://rstt.readthedocs.io/en/latest/rstt.ranking.html#rstt.ranking.ranking.Ranking) is a composition over inheritance design that contains:\n",
    "- A **[Standing](https://rstt.readthedocs.io/en/latest/rstt.ranking.html#rstt.ranking.standing.Standing)**: dict/list hybrid container. **Automaticaly sorts player** based on their *ranking point*.\n",
    "- A **[RatingSystem](https://rstt.readthedocs.io/en/latest/rstt.html#rstt.stypes.RatingSystem)**: dict like container that **maps player with ratings**\n",
    "- An **[Inference](https://rstt.readthedocs.io/en/latest/rstt.html#rstt.stypes.Inference)**: provides a **.rate method()** to compute ratings\n",
    "- An **[Observer](https://rstt.readthedocs.io/en/latest/rstt.html#rstt.stypes.Observer)**: provides a **.handle_observations()** method that process ranking.update inputs.\n",
    "\n",
    "Before integrating external system, lets start with a simple illustration.\n",
    "A ranking can be instanciated with its components specified. However, we recommand to represent a ranking design in its own class. It makes it more clear what parameters are intresect to the ranking design, and which are hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c526ce-14ae-4acb-876d-91dbd73bf42f",
   "metadata": {},
   "source": [
    "#### 1.1 Instanciate with Components\n",
    "\n",
    "A ranking can be instanciated with its components specified. NOT RECOMMANDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6e7d61-2333-4713-baae-b7fb12244573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rstt.ranking.ranking.Ranking at 0x11326b9e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rstt import Ranking\n",
    "from rstt.ranking import KeyModel, Elo, GameByGame\n",
    "\n",
    "# Ambiguity between core design elements and parameters. Is the handler a tunable parameter of the ranking?\n",
    "Ranking(name='elo', datamodel=KeyModel(default=1000), backend=Elo(k=20), handler=GameByGame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354b511-8b40-4690-b54f-f0ca04218c7d",
   "metadata": {},
   "source": [
    "#### 1.2 Class Design\n",
    "\n",
    "We recommand to represent a ranking design in its own class with an explicit naming. It makes it more clear what parameters are inherent to the ranking design, and which are tunable hyper-parameters for comparative studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cac3a4-ace7-43b2-9f46-2d7d687ebab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinguish core design from parameters, handler is not a parameter.\n",
    "class EloGBG(Ranking):\n",
    "    def __init__(self, name: str, default_rating: float=1000, k: float=20):\n",
    "        # The standing component provided in the super() init.\n",
    "        super().__init__(name=name,\n",
    "                         datamodel=KeyModel(default=default_rating), # RatingSystem\n",
    "                         backend=Elo(k=k), # Inference\n",
    "                         handler=GameByGame()) # Observer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e9917-6cf3-40dc-bc56-84afcee881e3",
   "metadata": {},
   "source": [
    "#### 1.3 Run illustration\n",
    "\n",
    "As you can see, there is not much to do and it works just fine in simulation. The RSTT built-in [BasicElo](https://rstt.readthedocs.io/en/latest/rstt.html#rstt.BasicElo) class code is in fact very similar.\n",
    "All ranking's functionalities are implemented at a higher level of abstraction and relies on minimal requirements from its components to work as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fba075-aab5-4ff9-8eee-9cc632e05425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- elo -----------\n",
      "   0.       Tiffany Vinson       1210\n",
      "   1.           Gary Young       1196\n",
      "   2.        Javier Henson       1192\n",
      "   3.     Antionette Welsh       1145\n",
      "   4.         Michael Mora       1130\n",
      "   5.        Joseph Austin       1130\n",
      "   6.       Shannon Monroe       1123\n",
      "   7.      Timothy Hubbard       1120\n",
      "   8.           Tim Cramer       1060\n",
      "   9.        Theresa Doyle       1055\n",
      "  10.         Linda Aberle       1047\n",
      "  11.        Matthew Salas       1038\n",
      "  12.        Beulah Mcgill       1031\n",
      "  13.      Tamica Martinez       1031\n",
      "  14.         Nancy Valdez       1027\n",
      "  15.        Charles Tracy       1015\n",
      "  16.        Donald Hauger        977\n",
      "  17.         Anthony Tong        973\n",
      "  18.        Stacie Parker        965\n",
      "  19.         Billy Hughes        941\n",
      "  20.          Susan Lesko        935\n",
      "  21.        Betty Mehling        932\n",
      "  22.       Richard Rosado        931\n",
      "  23.         Debra Ferris        924\n",
      "  24.     Howard Osterberg        921\n",
      "  25.       Donald Nuttall        900\n",
      "  26.         James Vasher        870\n",
      "  27.        Tracy Cordova        861\n",
      "  28.       Lorraine Walls        848\n",
      "  29.          Peggy Smith        842\n",
      "  30.         Megan Hinton        820\n",
      "  31.        Joanne Patton        794\n"
     ]
    }
   ],
   "source": [
    "from rstt import Player, RoundRobin, LogSolver\n",
    "\n",
    "# our ranking design\n",
    "elo = EloGBG('elo')\n",
    "\n",
    "# players\n",
    "population = Player.create(nb=32)\n",
    "\n",
    "# play games - ranking used as seeding\n",
    "tournament = RoundRobin('test', elo, LogSolver())\n",
    "tournament.registration(population)\n",
    "tournament.run()\n",
    "\n",
    "# check if update works\n",
    "elo.update(games=tournament.games())\n",
    "elo.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a6c9c2-485e-40ea-b603-d6c7fb2aad36",
   "metadata": {},
   "source": [
    "## 2. Use OpenSkill in RSTT\n",
    "\n",
    "[Openskill](https://github.com/vivekjoshy/openskill.py) is an Inference system according to RSTT terminology.\n",
    "On Github, it encourages to drop TrueSkill and Elo.\n",
    "So ... lets test it!\n",
    "\n",
    "#### 2.1 Ranking.datamodel: stypes.RatingSystem\n",
    "It acts as a container of rating object. It must provide get and set method for player's rating. It also provides a float interpretation of rating with an ordinal funciton. Lets first take a look at openskill rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0420fabf-ec35-4aeb-9e7c-ade1b0f07acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating data - mu: 25.0 sigma: 8.333333333333334 name: None id: 3db7d7a810ec4ea48d778f70bdfe652b\n"
     ]
    }
   ],
   "source": [
    "from openskill.models import PlackettLuce\n",
    "\n",
    "model = PlackettLuce()\n",
    "rating = model.rating()\n",
    "print('Rating data - mu:', rating.mu, 'sigma:', rating.sigma, 'name:', rating.name, 'id:', rating.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915db97-3a14-44a3-a3f4-d990e06d30e6",
   "metadata": {},
   "source": [
    "#### 2.2 KeyModel, a general purpose RatingSystem\n",
    "\n",
    "The [KeyModel](https://rstt.readthedocs.io/en/latest/rstt.ranking.html#module-rstt.ranking.datamodel) class is a base class for the RatingSystem protocol (see elo example). It provides all features needed and just require you to provide a default rating (for player that do not have one yet). \n",
    "\n",
    "There are 3 way to specify a default rating\n",
    "- by providing a value: **default** = model.rating()\n",
    "- by providing a constructor: **template** = model.rating\n",
    "- by providing a function which takes as input the player for which a rating is created: **factory** = lambda player: ...\n",
    "\n",
    "\n",
    "In the case of openskill, since rating do contain an id, it is better to avoid the default approach. The template is an option, but since rating have names, why not make it match the one player.name()? Let us use the factory approach.\n",
    "\n",
    "KeyModel has a basic ordinal implementation that will not work here. We need to overide it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3d5094-8636-4da1-9ae3-35e82b55622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plackett-Luce Player Data: \n",
      "\n",
      "id: 83c17cdd2b90447a8ae5fc350375410c\n",
      "name: dummy\n",
      "mu: 40\n",
      "sigma: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rstt.ranking import KeyModel\n",
    "\n",
    "class OSRatings(KeyModel):\n",
    "    def __init__(self, model, mu=None, sigma=None):\n",
    "        # the first parameter of the factory is always the player getting a rating\n",
    "        super().__init__(factory=lambda x, **kwargs: model.rating(name=x.name(), **kwargs), mu=mu, sigma=sigma)\n",
    "\n",
    "    def ordinal(self, rating) -> float:\n",
    "        # openskill ratings have an ordinal functionality themself - easy !\n",
    "        return rating.ordinal()\n",
    "\n",
    "osr = OSRatings(PlackettLuce(), mu=40, sigma=5)\n",
    "rating = osr.get(Player('dummy'))\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634cd601-3630-4753-b433-0ed84ffdd084",
   "metadata": {},
   "source": [
    "#### 2.2 Ranking.backend: stypes.Inference\n",
    "\n",
    "Inference is defined as a Protocol and typechecked in the RSTT package.\n",
    "Anything that provide a .rate() method fits the bill. Openskill.models have all a .rate method thus are RSTT.stypes.Inference and can directly be passed to a ranking class as backend. Nothing to do. Cool!\n",
    "\n",
    "This is not always the case. You can however write a simple class with a rate method that wrapps the rate process of a system to intergrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc462d-a52d-4f0b-9d6d-408d1e994011",
   "metadata": {},
   "source": [
    "#### 2.3 Ranking.handler: stypes.Observer\n",
    "\n",
    "The handler.handle_observations() method is called by the ranking.forward() during the ranking.update() execution. \n",
    "\n",
    "- Ranking.update is a user level functionnality that should **NEVER** be override.\n",
    "- Ranking.forward is a develloper functionnality. It **CAN** be override, usualy not necessary.\n",
    "- Observer.handle_observations  is a complete workflow from the update input to the new ranking state.\n",
    "\n",
    "In a majority of cases, the handle_observations perform the following steps:\n",
    "1) Format the update inputs. The inputs are referred as 'observations'. They justify a change of ranking state.\n",
    "2) Extract from the observations the relevant information\n",
    "3) Query the datamodel for the corresponding *prior* ratings\n",
    "4) Call the backend.rate method with correct arguments\n",
    "5) Interpret the backend.rate return values\n",
    "6) Push the *posteriori* ratings to the datamodel\n",
    "\n",
    "We want to input a list of RSTT.stypes.SMatch. We already have workedk on the ratings in the datamodel.\n",
    "We need to extract relevant data from games. So we need to know what to pass to the rate method. Lets have a look at its signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ab3b2c-f0a7-49e3-b8d0-9548a179b106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return': typing.List[typing.List[openskill.models.weng_lin.plackett_luce.PlackettLuceRating]],\n",
       " 'teams': typing.List[typing.List[openskill.models.weng_lin.plackett_luce.PlackettLuceRating]],\n",
       " 'ranks': typing.Optional[typing.List[float]],\n",
       " 'scores': typing.Optional[typing.List[float]],\n",
       " 'tau': typing.Optional[float],\n",
       " 'limit_sigma': typing.Optional[bool]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getfullargspec(model.rate).annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a1761-54ff-4558-81e6-cfe78cee4d31",
   "metadata": {},
   "source": [
    "**TODO:** Your Task is to read the Observer code and try to identify the 6 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f27d25-407a-479b-abc5-ebc2c6de423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rstt.stypes import RatingSystem, Inference, SMatch\n",
    "\n",
    "class OSHandler:\n",
    "    def handle_observations(self, datamodel: RatingSystem, infer: Inference, games: list[SMatch]):\n",
    "        for game in games:\n",
    "            # extract game info\n",
    "            teams_of_players = game.teams()\n",
    "            scores = game.scores() # alternative: ranks = game.ranks()\n",
    "            \n",
    "            # get corresponding rating from datamodel\n",
    "            teams = [] # list[list[rating]]\n",
    "            for team in teams_of_players:\n",
    "                ratings = [] # list[rating]\n",
    "                for player in team:\n",
    "                    ratings.append(datamodel.get(player))\n",
    "                teams.append(ratings)\n",
    "            \n",
    "            # call rate\n",
    "            new_ratings = infer.rate(teams=teams, scores=scores) # or ..., ranks=ranks)\n",
    "            \n",
    "            # push new ratings\n",
    "            for team, ratings in zip(teams_of_players, new_ratings):\n",
    "                for player, rating in zip(team, ratings):\n",
    "                    datamodel.set(player, rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3b6fa-bf78-46f2-ae9e-a1a3579c1eb2",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "- step1: no formating, if the user does not pass a list of games, the observer will not work\n",
    "- step2: games.teams() and games.scores()\n",
    "- step3: datamodel.get() calls\n",
    "- step4: infer.rate() call\n",
    "- step5: the *for ... in zip(...)* matches the output of the rate method with the adequate players in simulations\n",
    "- step6: datamodel.set() calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abfd0a-0693-4004-af1a-78150ece5cdc",
   "metadata": {},
   "source": [
    "#### 2.4 Run illustration\n",
    "\n",
    "The OpenSkill Ranking class will take one single parameter, an openskill.models object. And then it is ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aef242e6-354c-4630-8494-94bfa94fed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Openskill class\n",
    "class OpenSkill(Ranking):\n",
    "    def __init__(self, name: str, model):\n",
    "        super().__init__(name=name, datamodel=OSRatings(model), backend=model, handler=OSHandler())\n",
    "\n",
    "# OS Instance\n",
    "os = OpenSkill('OpenSkill', model)\n",
    "\n",
    "# OS update on rstt simulated games\n",
    "os.update(games=tournament.games())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec15413d-2c7a-4f7b-b1a4-9b35539f2ab5",
   "metadata": {},
   "source": [
    "**Remark:** RSTT provides an OpenSkill ranking wrapper - [BasicOS](https://rstt.readthedocs.io/en/latest/rstt.html#rstt.BasicOS) - which is not exactly implemented as present in the tutorials, but works similary. You still need to import Openskill and pass a model yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ff975-63f1-4fa4-ad52-378bfd67ac1a",
   "metadata": {},
   "source": [
    "## 3. Ranking functionality\n",
    "\n",
    "This is now openskill on steroÃ¯ds. You can access playesr by ranks, get rating of a player. You can use it to seed competition like a single elimination bracket. Lets start by a standard output plot of the standing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8832f74-66e0-42f5-8234-d9a28cf14b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- OpenSkill -----------\n",
      "   0.       Tiffany Vinson         35\n",
      "   1.           Gary Young         33\n",
      "   2.        Javier Henson         31\n",
      "   3.     Antionette Welsh         27\n",
      "   4.         Michael Mora         26\n",
      "   5.        Joseph Austin         24\n",
      "   6.      Timothy Hubbard         24\n",
      "   7.       Shannon Monroe         24\n",
      "   8.           Tim Cramer         17\n",
      "   9.         Linda Aberle         16\n",
      "  10.        Theresa Doyle         16\n",
      "  11.        Beulah Mcgill         16\n",
      "  12.        Matthew Salas         15\n",
      "  13.      Tamica Martinez         14\n",
      "  14.        Charles Tracy         13\n",
      "  15.         Nancy Valdez         12\n",
      "  16.        Donald Hauger          9\n",
      "  17.         Anthony Tong          8\n",
      "  18.        Stacie Parker          7\n",
      "  19.         Billy Hughes          5\n",
      "  20.          Susan Lesko          4\n",
      "  21.        Betty Mehling          3\n",
      "  22.       Richard Rosado          3\n",
      "  23.         Debra Ferris          3\n",
      "  24.     Howard Osterberg          2\n",
      "  25.       Donald Nuttall          0\n",
      "  26.         James Vasher         -2\n",
      "  27.        Tracy Cordova         -4\n",
      "  28.       Lorraine Walls         -6\n",
      "  29.          Peggy Smith         -8\n",
      "  30.         Megan Hinton        -10\n",
      "  31.        Joanne Patton        -15\n"
     ]
    }
   ],
   "source": [
    "os.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83069a82-db05-4207-9e9b-76ab0b7e1199",
   "metadata": {},
   "source": [
    "#### 3.1 Rank Correlation\n",
    "\n",
    "RSTT ranking interface simplifies some metrics compuation, like rank correlation. The advantage of simulation is that you have a baseline to comupte it. Lets compare elo and openskill to the simulation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acbf573c-e104-4fdf-9a76-04b864cbe811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSkill - GroundTRuth correlation: \n",
      "   SignificanceResult(statistic=np.float64(0.8508064516129034), pvalue=np.float64(8.187631748655122e-17))\n",
      "Elo - GroundTRuth correlation: \n",
      "   SignificanceResult(statistic=np.float64(0.866935483870968), pvalue=np.float64(7.496744126671432e-18))\n",
      "OpenSkill - Elo correlation: \n",
      "   SignificanceResult(statistic=np.float64(0.9838709677419356), pvalue=np.float64(3.9371288142144177e-31))\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from rstt import BTRanking\n",
    "\n",
    "# ranking where players ratings are their respectives level(). \n",
    "gt = BTRanking('consensus', population)\n",
    "\n",
    "print('OpenSkill - GroundTRuth correlation: \\n  ', stats.kendalltau(gt[population], os[population]))\n",
    "print('Elo - GroundTRuth correlation: \\n  ', stats.kendalltau(gt[population], elo[population]))\n",
    "print('OpenSkill - Elo correlation: \\n  ', stats.kendalltau(elo[population], os[population]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d880a68-de8c-40a7-864d-093987f7e120",
   "metadata": {},
   "source": [
    "#### 3.2 Ranking state as simulation parameter\n",
    "\n",
    "You can easly play arround with the inital state of any RSTT ranking by provding an arbitrary ordering of the players involved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b258379a-e748-4225-ae78-8a5733b7a18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[14, 10, 28, 3, 27, 26, 16, 17, 23, 22, 4, 0, 2, 13, 1, 11, 18, 30, 12, 24, 29, 20, 15, 31, 7, 8, 6, 21, 5, 9, 19, 25]\n",
      "Seeds - Truth correlation: -0.00806451612903226\n",
      "OpenSkill - GroundTRuth correlation: -0.00403225806451613\n",
      "Elo - GroundTRuth correlation: -0.00403225806451613\n",
      "OpenSkill - Elo correlation: 0.7822580645161291\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# random ordering\n",
    "seeds = list(range(len(os)))\n",
    "random.shuffle(seeds)\n",
    "\n",
    "print(list(range(len(os))))\n",
    "print(seeds)\n",
    "print('Seeds - Truth correlation:', stats.kendalltau(seeds, list(range(len(os)))).statistic)\n",
    "\n",
    "# reordering\n",
    "elo.rerank(seeds)\n",
    "os.rerank(seeds)\n",
    "\n",
    "print('OpenSkill - GroundTRuth correlation:', stats.kendalltau(gt[population], os[population]).statistic)\n",
    "print('Elo - GroundTRuth correlation:', stats.kendalltau(gt[population], elo[population]).statistic)\n",
    "print('OpenSkill - Elo correlation:', stats.kendalltau(elo[population], os[population]).statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade7bac-1f56-4129-b3fb-2e3dfdbe7ede",
   "metadata": {},
   "source": [
    "#### 3.3 Control the Interplay between a Ranking and a Dataset\n",
    "\n",
    "Now it is possible to select players and seed them in a competition based on their openskill ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7a9306c-aedf-42df-8ca7-b6660fa54768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rstt import SwissRound\n",
    "\n",
    "# reordered openskill ranking as seeding\n",
    "t2 = SwissRound(name='OpensKill seeded tournament', seeding=os, solver=LogSolver())\n",
    "\n",
    "# top 16 players according to openskill\n",
    "t2.registration(os[:16])\n",
    "t2.run()\n",
    "\n",
    "os.update(games=t2.games())\n",
    "elo.update(games=t2.games())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa3bce-3b0f-47fe-87c4-2e60888edf43",
   "metadata": {},
   "source": [
    "#### 3.4 Fancy Analysis\n",
    "\n",
    "Let see what changed. Keep in mind that we atrificialy altered the entire ranking state, but only half of the players where involved in the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4bad345-d9d6-49cf-906d-c863ac94d5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Kendalltau rank correaltion on the entire population --\n",
      "OpenSkill - GroundTRuth correlation: 0.08064516129032259\n",
      "Elo - GroundTRuth correlation: 0.08467741935483872\n",
      "OpenSkill - Elo correlation: 0.7943548387096775\n",
      "\n",
      " -- Kendalltau rank correaltion on the real top16 --\n",
      "OpenSkill - GroundTRuth correlation: 0.0\n",
      "Elo - GroundTRuth correlation: 0.0\n",
      "OpenSkill - Elo correlation: 0.6333333333333333\n",
      "\n",
      " -- Kendalltau rank correaltion on the 'openskill prio' top16 --\n",
      "OpenSkill - GroundTRuth correlation: 0.26666666666666666\n",
      "Elo - GroundTRuth correlation: 0.15\n",
      "OpenSkill - Elo correlation: 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "print('-- Kendalltau rank correaltion on the entire population --')\n",
    "print('OpenSkill - GroundTRuth correlation:', stats.kendalltau(gt[population], os[population]).statistic)\n",
    "print('Elo - GroundTRuth correlation:', stats.kendalltau(gt[population], elo[population]).statistic)\n",
    "print('OpenSkill - Elo correlation:', stats.kendalltau(elo[population], os[population]).statistic)\n",
    "\n",
    "print('\\n -- Kendalltau rank correaltion on the real top16 --')\n",
    "top16 = gt[:16]\n",
    "print('OpenSkill - GroundTRuth correlation:', stats.kendalltau(gt[top16], os[top16]).statistic)\n",
    "print('Elo - GroundTRuth correlation:', stats.kendalltau(gt[top16], elo[top16]).statistic)\n",
    "print('OpenSkill - Elo correlation:', stats.kendalltau(elo[top16], os[top16]).statistic)\n",
    "\n",
    "print('\\n -- Kendalltau rank correaltion on the \\'openskill prio\\' top16 --')\n",
    "seed16 = t2.participants()\n",
    "print('OpenSkill - GroundTRuth correlation:', stats.kendalltau(gt[seed16], os[seed16]).statistic)\n",
    "print('Elo - GroundTRuth correlation:', stats.kendalltau(gt[seed16], elo[seed16]).statistic)\n",
    "print('OpenSkill - Elo correlation:', stats.kendalltau(elo[seed16], os[seed16]).statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb5315-7c51-4eea-8790-5e4b84f41884",
   "metadata": {},
   "source": [
    "## 4 OpenSkill as Solver\n",
    "\n",
    "A Solver is anything that provide a solve() method. It is used to assign a Score to SMatch. Because OpenSkill has methods to predict game outcome, it could be used has a solver. Below is an example for Duel confrontation. we are extending the Solver ScoreProb which generate game outcome based on a score probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7936845f-859c-476b-b31c-a40b8f73d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rstt.solver.solvers import ScoreProb, WIN, LOSE\n",
    "from rstt import Duel\n",
    "\n",
    "import random\n",
    "\n",
    "# OpenSkill Solver\n",
    "class OSS(ScoreProb):\n",
    "    def __init__(self, os: OpenSkill):\n",
    "        self.model = os.backend\n",
    "        self.ratings = os.datamodel\n",
    "        \n",
    "        # NOTE: WIN is an alias for player1 wins; LOSE if an alias for player1 lose, i.e player2 wins\n",
    "        super().__init__(scores=[WIN, LOSE], func=self.predict_win)\n",
    "\n",
    "    def predict_win(self, duel: Duel) -> list[float]:\n",
    "        # NOTE: when player1 wins, then player2 lose and vice-versa\n",
    "        return self.model.predict_win([[self.ratings.get(duel.player1())], [self.ratings.get(duel.player2())]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7e928-8117-4a98-b546-f4c0aa790a3e",
   "metadata": {},
   "source": [
    "#### 4.1 Level Coherence\n",
    "\n",
    "The OSS class does not care about involved player's level. It needs OpenSkill ratings, which is completely indepandent. Player with high level having less than 0.5 win probability against player with lower level can be confusing. One way to keep the Player base class coherent with the solver is to train the rating on an *ideal dataset*, one where every player faces each others at least once and the best player wins the encounters.  We can use [RoundRobin](https://rstt.readthedocs.io/en/latest/rstt.scheduler.tournament.html#rstt.scheduler.tournament.groups.RoundRobin) and [BetterWin](https://rstt.readthedocs.io/en/latest/rstt.solver.html#rstt.solver.solvers.BetterWin) for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1eece45-4d8e-486c-aadb-b463847a3d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSkill - GroundTRuth correlation: 1.0\n"
     ]
    }
   ],
   "source": [
    "from openskill.models import BradleyTerryFull\n",
    "from rstt import BetterWin\n",
    "\n",
    "# Perfect Data Set\n",
    "training_set = RoundRobin('Training Set', seeding=gt, solver=BetterWin())\n",
    "training_set.registration(population)\n",
    "training_set.run()\n",
    "\n",
    "# Train OpenSkill -> make meaningfull ratings\n",
    "os_trained = OpenSkill('OpenSkill as Solver', model=BradleyTerryFull())\n",
    "os_trained.update(games=training_set.games())\n",
    "\n",
    "# assert ranking quality\n",
    "print('OpenSkill - GroundTRuth correlation:', stats.kendalltau(gt[population], os_trained[population]).statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833745df-a1a5-4b53-81b9-059c19909369",
   "metadata": {},
   "source": [
    "#### 4.2 Simulation\n",
    "\n",
    "And now we can instanciate and run competition sublass by providing OSS as a solver. The game results are generated according to OpenSkill model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce416792-1ee5-45bc-8af3-abf77e7cab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSS solver defines the truth level - After Single-Elimination-Bracket\n",
      "GroundTRuth - Glicko correlation: 0.5967741935483871\n",
      "GroundTRuth - BTS correlation: 0.5967741935483871\n",
      "OSS solver defines the truth level - After Swiss-Bracket\n",
      "GroundTRuth - Glicko correlation: 0.4435483870967743\n",
      "GroundTRuth - BTS correlation: 0.7500000000000001\n"
     ]
    }
   ],
   "source": [
    "from rstt import SingleEliminationBracket, SwissBracket\n",
    "from rstt import BasicGlicko\n",
    "\n",
    "# OpenSkill as Solver\n",
    "oss = OSS(os_trained)\n",
    "\n",
    "# test ranking\n",
    "gl = BasicGlicko('Glicko')\n",
    "btf = OpenSkill('BTF tested', model=BradleyTerryFull())\n",
    "\n",
    "# play games using openskill prediction to generate scores\n",
    "seb = SingleEliminationBracket('Example SEB', seeding=gt, solver=oss)\n",
    "seb.registration(population)\n",
    "seb.run()\n",
    "\n",
    "\n",
    "print('OSS solver defines the truth level - After Single-Elimination-Bracket')\n",
    "gl.update(games=seb.games())\n",
    "btf.update(games=seb.games())\n",
    "print('GroundTRuth - Glicko correlation:', stats.kendalltau(os_trained[population], gl[population]).statistic)\n",
    "print('GroundTRuth - BTS correlation:', stats.kendalltau(os_trained[population], btf[population]).statistic)\n",
    "\n",
    "# play games using openskill prediction to generate scores\n",
    "swb = SwissBracket('Example SwissBracket', seeding=gt, solver=oss)\n",
    "swb.registration(population[:16])\n",
    "swb.run()\n",
    "\n",
    "print('OSS solver defines the truth level - After Swiss-Bracket')\n",
    "gl.update(games=seb.games())\n",
    "btf.update(games=swb.games())\n",
    "print('GroundTRuth - Glicko correlation:', stats.kendalltau(os_trained[population], gl[population]).statistic)\n",
    "print('GroundTRuth - BTS correlation:', stats.kendalltau(os_trained[population], btf[population]).statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8b4a8-d5fb-4dda-84bc-d73b3b5ccfcd",
   "metadata": {},
   "source": [
    "## 5. Your Turn - Trueskill\n",
    "\n",
    "[Trueskill](https://trueskill.org) also fits the RSTT.stypes.Inference interface with a rate method. You know how to use it now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b15b19-a457-4fd1-8a2d-6be843d36751",
   "metadata": {},
   "source": [
    "## 6. Your Turn - Real Data\n",
    "\n",
    "Running rstt ranking on real dataset is not hard? Do you have an idea how to make it work?\n",
    "\n",
    "That is right. You write an observer! The component that deals with the update input. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
